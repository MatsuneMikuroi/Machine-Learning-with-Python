# Machine Learning with Python
[![langfr](https://img.shields.io/badge/lang-fr-blue)]( <README.fr.md> )  
This repository contain all the exercises of the course [Machine Learning with Python]( https://www.coursera.org/learn/machine-learning-with-python/home/info ) given by [Joseph Santarcangelo]( https://www.coursera.org/instructor/~28511493 ) and [Jeff Grossman
]( https://www.coursera.org/instructor/jeffgrossman ) on [Coursera]( https://www.coursera.org/instructor/~28511493 ) during the formation [IBM Data Science Professional Certificate]( https://www.coursera.org/professional-certificates/ibm-data-science ).

## Module 1
This module provides knowledge of foundational machine learning concepts to delve deeper into applied machine learning modeling. It presents the following points:
- that machine learning modeling is an iterative process with various lifecycle stages,
- the daily activities in the life of a machine learning engineer.
- an introduction to various open-source tools for machine learning, including the popular Python package scikit-learn.

## Module 2
The goal of this module is to explore two foundational statistical modeling methods, linear regression and logistic regression, which are considered classical machine learning models. Linear regression, often applied in real-world problem-solving, models a linear relationship between independent variables and a dependent variable. Logistic regression, an extension of linear regression, functions as a classifier and can handle nonlinear relationships through input transformation. By implementing these models, you'll gain insight into their limitations and better understand the advancements offered by modern machine learning models.

[![Static Badge](https://img.shields.io/badge/1-Simple%20Linear%20Regression-yellow)](1Simple-Linear-Regression.ipynb)
[![Static Badge](https://img.shields.io/badge/2-Mulitple%20Linear%20Regression-yellow)](2Mulitple-Linear-Regression.ipynb)
[![Static Badge](https://img.shields.io/badge/3-Logistic%20Regression-yellow)](3Logistic-Regression.ipynb)


## Module 3
This module is about implementing modern supervised machine learning models, starting by understanding how binary classification works and discover how to construct a multiclass classifier from binary classification components. It presents what decision trees are, how they learn, and how to build them. Decision trees, which are used to solve classification problems, have a natural extension called regression trees, which can handle regression problems. Other supervised learning models, such as KNN and SVM are also viewed. Concepts such as bias and variance are in model fitting and the tradeoff between bias and variance inherent to all learning models in various degrees are presented. This module also developp strategies for mitigating this tradeoff and work with models that do a very good job accomplishing that goal.

[![Static Badge](https://img.shields.io/badge/4-Multi%20class%20Classification-yellow)](4Multi-class-Classification.ipynb)
[![Static Badge](https://img.shields.io/badge/5-Decision%20tree%20classifier%20drug%20pred-yellow)](5Decision-tree-classifier-drug-pred.ipynb)
[![Static Badge](https://img.shields.io/badge/6-Regression%20Trees%20Taxi%20Tip-yellow)](6Regression-Trees-Taxi-Tip.ipynb)
[![Static Badge](https://img.shields.io/badge/7-decision%20tree%20svm%20ccFraud-yellow)](7decision-tree-svm-ccFraud.ipynb)
[![Static Badge](https://img.shields.io/badge/8-KNN-yellow)](8KNN.ipynb)
[![Static Badge](https://img.shields.io/badge/9-Random%20Forests%20XGBoost-yellow)](9Random-Forests-XGBoost.ipynb)


## Module 4
This module explore unsupervised learning, a machine-learning approach that doesn't require labeled data. Instead of using correct answers, these algorithms identify patterns in data based on similarity. These patterns form clusters in an N-dimensional feature space, where data points that are close together can be considered clusters. Clusters may have a hierarchical structure, similar to natural systems such as galaxies or biological taxonomies. It is also about clustering algorithms and how unsupervised learning can reduce features for other modeling tasks, using Python to implement various clustering and dimensionality reduction techniques.

[![Static Badge](https://img.shields.io/badge/10-K%20Means%20Customer%20Seg-yellow)](10K-Means-Customer-Seg.ipynb)
[![Static Badge](https://img.shields.io/badge/11-Comparing%20DBScan%20HDBScan-yellow)](11Comparing-DBScan-HDBScan.ipynb)
[![Static Badge](https://img.shields.io/badge/12-PCA-yellow)](12PCA.ipynb)
[![Static Badge](https://img.shields.io/badge/13-tSNE%20UMAP-yellow)](13tSNE-UMAP.ipynb)


## Module 5
This module is about how to evaluate the performance of supervised machine learning models using various metrics, depending on whether we are building classification or regression models. It explores hyperparameter tuning techniques like cross-validation to prevent overfitting and ensure an unbiased model evaluation. Additionally, it is about regularization techniques for linear regression to mitigate overfitting caused by noise and outliers. Finally, hands-on experience in building, fine-tuning, and evaluating models using these techniques are provided.

[![Static Badge](https://img.shields.io/badge/14-Evaluating%20Classification%20Models-yellow)](14Evaluating-Classification-Models.ipynb)
[![Static Badge](https://img.shields.io/badge/15-Evaluating%20random%20forest-yellow)](15Evaluating-random-forest.ipynb)
[![Static Badge](https://img.shields.io/badge/16-Evaluating%20k%20means%20clustering-yellow)](16Evaluating-k-means-clustering.ipynb)
[![Static Badge](https://img.shields.io/badge/17-Regularization%20in%20LinearRegression-yellow)](17Regularization-in-LinearRegression.ipynb)
[![Static Badge](https://img.shields.io/badge/18-ML%20Pipelines%20and%20GridSearchCV-yellow)](18ML-Pipelines-and-GridSearchCV.ipynb)


## Module 6
This module focuses on applying and demonstrating the skills gained throughout the course by completing a comprehensive final assignment. In this assignment, include analyze historical rainfall data to develop and optimize a classification model.

[![Static Badge](https://img.shields.io/badge/19-Practic%20Project-yellow)](19Practic-Project.ipynb)
